{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596013c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required classes and packages\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt   \n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import  MaxPooling2D\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, AveragePooling2D\n",
    "from keras.layers import Convolution2D\n",
    "from keras.models import Sequential, load_model, Model\n",
    "import pickle\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "import requests\n",
    "import numpy_encoder\n",
    "import json\n",
    "from keras.applications import VGG19\n",
    "from ultralytics import YOLO\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d75f2d5-249d-4a51-9b98-6d215868b4cb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#yolo confidence threshold to detect skin disorder\n",
    "CONFIDENCE_THRESHOLD = 0.50\n",
    "GREEN = (0, 255, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746fe450",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define and load class labels found in dataset\n",
    "path = \"Dataset\"\n",
    "labels = []\n",
    "X = []\n",
    "Y = []\n",
    "for root, dirs, directory in os.walk(path):\n",
    "    for j in range(len(directory)):\n",
    "        name = os.path.basename(root)\n",
    "        if name not in labels:\n",
    "            labels.append(name.strip())   \n",
    "print(\"Skin Disease Class Labels : \"+str(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92463d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define function to get class label of given image\n",
    "def getLabel(name):\n",
    "    index = -1\n",
    "    for i in range(len(labels)):\n",
    "        if labels[i] == name:\n",
    "            index = i\n",
    "            break\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edad6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataset image and process them\n",
    "if os.path.exists(\"model/X.txt.npy\"):\n",
    "    X = np.load('model/X.txt.npy')\n",
    "    Y = np.load('model/Y.txt.npy')\n",
    "else: #if images not process then read and process image pixels\n",
    "    for root, dirs, directory in os.walk(path):#connect to dataset folder\n",
    "        for j in range(len(directory)):#loop all images from dataset folder\n",
    "            name = os.path.basename(root)\n",
    "            if 'Thumbs.db' not in directory[j]:\n",
    "                img = cv2.imread(root+\"/\"+directory[j])#read images\n",
    "                img = cv2.resize(img, (32, 32))#resize image\n",
    "                X.append(img) #add image pixels to X array\n",
    "                label = getLabel(name)#get image label id\n",
    "                Y.append(label)#add image label                \n",
    "    X = np.asarray(X)#convert array as numpy array\n",
    "    Y = np.asarray(Y)\n",
    "    indices = np.arange(X.shape[0])\n",
    "    np.random.shuffle(indices)#shuffle images\n",
    "    X = X[indices]\n",
    "    Y = Y[indices]\n",
    "    np.save('model/X.txt',X)#save process images and labels\n",
    "    np.save('model/Y.txt',Y)\n",
    "print(\"Dataset images loaded\")\n",
    "print(\"Total images found in dataset : \"+str(X.shape[0]))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863bcef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualizing class labels count found in dataset\n",
    "names, count = np.unique(Y, return_counts = True)\n",
    "height = count\n",
    "bars = labels\n",
    "y_pos = np.arange(len(bars))\n",
    "plt.figure(figsize = (6, 3)) \n",
    "plt.bar(y_pos, height)\n",
    "plt.xticks(y_pos, bars)\n",
    "plt.xlabel(\"Dataset Class Label Graph\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e951dd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess images like normalization\n",
    "X = X.astype('float32')\n",
    "X = X/255 #normalized pixel values between 0 and 1\n",
    "#divide dataset into two clients\n",
    "client1_X = X\n",
    "client1_Y = Y\n",
    "client2_X = X[2501:X.shape[0]]\n",
    "client2_Y = Y[2501:X.shape[0]]\n",
    "client1_Y = to_categorical(client1_Y)\n",
    "client2_Y = to_categorical(client2_Y)\n",
    "#split both client dataset into train and test\n",
    "client1_X_train, client1_X_test, client1_y_train, client1_y_test = train_test_split(client1_X, client1_Y, test_size=0.2)\n",
    "client2_X_train, client2_X_test, client2_y_train, client2_y_test = train_test_split(client2_X, client2_Y, test_size=0.2) #split dataset into train and test\n",
    "print(\"Client1 Training Size 80% = \"+str(client1_X_train.shape[0]))\n",
    "print(\"Client1 Testing Size 20%  = \"+str(client1_X_test.shape[0]))\n",
    "print(\"Client2 Training Size 80% = \"+str(client2_X_train.shape[0]))\n",
    "print(\"Client2 Testing Size 20%  = \"+str(client2_X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abb331a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define global variables to save accuracy and other metrics\n",
    "accuracy = []\n",
    "precision = []\n",
    "recall = []\n",
    "fscore = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6622bb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateMetrics(algorithm, predict, y_test):\n",
    "    a = accuracy_score(y_test,predict)*100\n",
    "    p = precision_score(y_test, predict,average='macro') * 100\n",
    "    r = recall_score(y_test, predict,average='macro') * 100\n",
    "    f = f1_score(y_test, predict,average='macro') * 100\n",
    "    accuracy.append(a)\n",
    "    precision.append(p)\n",
    "    recall.append(r)\n",
    "    fscore.append(f)\n",
    "    print(algorithm+\" Accuracy  :  \"+str(a))\n",
    "    print(algorithm+\" Precision : \"+str(p))\n",
    "    print(algorithm+\" Recall    : \"+str(r))\n",
    "    print(algorithm+\" FScore    : \"+str(f))    \n",
    "    conf_matrix = confusion_matrix(y_test, predict) \n",
    "    plt.figure(figsize =(6, 5)) \n",
    "    ax = sns.heatmap(conf_matrix, xticklabels = labels, yticklabels = labels, annot = True, cmap=\"viridis\" ,fmt =\"g\");\n",
    "    ax.set_ylim([0,len(labels)])\n",
    "    plt.title(algorithm+\" Confusion matrix\") \n",
    "    plt.xticks(rotation=90)\n",
    "    plt.ylabel('True class') \n",
    "    plt.xlabel('Predicted class') \n",
    "    plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bda2f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training CNN model on client1 dataset\n",
    "client1_cnn_model = Sequential()\n",
    "client1_cnn_model.add(Convolution2D(32, (3 , 3), input_shape = (client1_X_train.shape[1], client1_X_train.shape[2], client1_X_train.shape[3]), activation = 'relu'))\n",
    "client1_cnn_model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "client1_cnn_model.add(Convolution2D(32, (3, 3), activation = 'relu'))\n",
    "client1_cnn_model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "client1_cnn_model.add(Flatten())\n",
    "client1_cnn_model.add(Dense(units = 256, activation = 'relu'))\n",
    "client1_cnn_model.add(Dense(units = client1_y_train.shape[1], activation = 'softmax'))\n",
    "client1_cnn_model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "if os.path.exists(\"model/client1_weights.hdf5\") == False:\n",
    "    model_check_point = ModelCheckpoint(filepath='model/client1_weights.hdf5', verbose = 1, save_best_only = True)\n",
    "    hist = client1_cnn_model.fit(client1_X_train, client1_y_train, batch_size = 32, epochs = 30, validation_data=(client1_X_test, client1_y_test), callbacks=[model_check_point], verbose=1)\n",
    "    f = open('model/client1_history.pckl', 'wb')\n",
    "    pickle.dump(hist.history, f)\n",
    "    f.close()    \n",
    "else:\n",
    "    client1_cnn_model.load_weights(\"model/client1_weights.hdf5\")\n",
    "#perform prediction on test data\n",
    "predict = client1_cnn_model.predict(client1_X_test)\n",
    "predict = np.argmax(predict, axis=1)\n",
    "y_test1 = np.argmax(client1_y_test, axis=1)\n",
    "#call this function to calculate accuracy\n",
    "calculateMetrics(\"CNN Client1 Local\", predict, y_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88afdc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#update client1 cnn local model to Federated server\n",
    "client1_weight = client1_cnn_model.get_weights()#get weights of client1 model\n",
    "local_weight_to_json = json.dumps(client1_weight, cls=numpy_encoder.NumpyEncoder)#convert weight to json\n",
    "requests.put('http://127.0.0.1:8000/update', data=local_weight_to_json)#send weight to given URL federated server\n",
    "print(\"Client1 weights send to Federated Server\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a4aa3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train CNN model on Client2 dataset\n",
    "client2_cnn_model = Sequential()\n",
    "client2_cnn_model.add(Convolution2D(32, (3 , 3), input_shape = (client2_X_train.shape[1], client2_X_train.shape[2], client2_X_train.shape[3]), activation = 'relu'))\n",
    "client2_cnn_model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "client2_cnn_model.add(Convolution2D(32, (3, 3), activation = 'relu'))\n",
    "client2_cnn_model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "client2_cnn_model.add(Flatten())\n",
    "client2_cnn_model.add(Dense(units = 256, activation = 'relu'))\n",
    "client2_cnn_model.add(Dense(units = client2_y_train.shape[1], activation = 'softmax'))\n",
    "client2_cnn_model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "if os.path.exists(\"model/client2_weights.hdf5\") == False:\n",
    "    model_check_point = ModelCheckpoint(filepath='model/client2_weights.hdf5', verbose = 1, save_best_only = True)\n",
    "    hist = client2_cnn_model.fit(client2_X_train, client2_y_train, batch_size = 32, epochs = 30, validation_data=(client2_X_test, client2_y_test), callbacks=[model_check_point], verbose=1)\n",
    "    f = open('model/client2_history.pckl', 'wb')\n",
    "    pickle.dump(hist.history, f)\n",
    "    f.close()    \n",
    "else:\n",
    "    client2_cnn_model.load_weights(\"model/client2_weights.hdf5\")\n",
    "#perform prediction on test data   \n",
    "predict = client2_cnn_model.predict(client2_X_test)\n",
    "predict = np.argmax(predict, axis=1)\n",
    "y_test1 = np.argmax(client2_y_test, axis=1)\n",
    "#call this function to calculate accuracy\n",
    "calculateMetrics(\"CNN Client2 Local\", predict, y_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a881cfbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#update client2 weights to federated server\n",
    "client2_weights = client2_cnn_model.get_weights()#get weights of client1 model\n",
    "local_weight_to_json = json.dumps(client2_weights, cls=numpy_encoder.NumpyEncoder)#convert weight to json\n",
    "requests.put('http://127.0.0.1:8000/update', data=local_weight_to_json)#send weight to given URL federated server\n",
    "print(\"Client2 weights send to Federated Server\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9259202d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now get weights from federated server to form global model\n",
    "result = requests.get('http://127.0.0.1:8000/weight')#get weights from federated server\n",
    "result_data = result.json()\n",
    "global_weight = None\n",
    "if result_data is not None:\n",
    "    global_weight = []\n",
    "    for i in range(len(result_data)):#loop all clients weights and append to global weight\n",
    "        temp = np.array(result_data[i])\n",
    "        global_weight.append(temp)\n",
    "    global_weight = np.asarray(global_weight)\n",
    "#split main data to train and test to perform prediction using global model\n",
    "Y1 = to_categorical(Y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y1, test_size=0.2) #split dataset into train and test\n",
    "#creating global model architecture\n",
    "global_model = Sequential()\n",
    "global_model.add(Convolution2D(32, (3 , 3), input_shape = (X_train.shape[1], X_train.shape[2], X_train.shape[3]), activation = 'relu'))\n",
    "global_model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "global_model.add(Convolution2D(32, (3, 3), activation = 'relu'))\n",
    "global_model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "global_model.add(Flatten())\n",
    "global_model.add(Dense(units = 256, activation = 'relu'))\n",
    "global_model.add(Dense(units = y_train.shape[1], activation = 'softmax'))\n",
    "global_model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "#set global weight to global model\n",
    "global_model.set_weights(global_weight)\n",
    "#perform prediction on test data using global model weights\n",
    "predict = global_model.predict(X_test)\n",
    "predict = np.argmax(predict, axis=1)\n",
    "y_test1 = np.argmax(y_test, axis=1)\n",
    "#call this function to calculate accuracy\n",
    "calculateMetrics(\"CNN Global Model\", predict, y_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63d34ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train VGG19 algorithm\n",
    "vgg = VGG19(input_shape=(X_train.shape[1], X_train.shape[2], X_train.shape[3]), include_top=False, weights='imagenet')\n",
    "for layer in vgg.layers:\n",
    "    layer.trainable = False\n",
    "headModel = vgg.output\n",
    "headModel = AveragePooling2D(pool_size=(1, 1))(headModel)\n",
    "headModel = Flatten(name=\"flatten\")(headModel)\n",
    "headModel = Dense(128, activation=\"relu\")(headModel)\n",
    "headModel = Dropout(0.3)(headModel)\n",
    "headModel = Dense(y_train.shape[1], activation=\"softmax\")(headModel)\n",
    "vgg_model = Model(inputs=vgg.input, outputs=headModel)\n",
    "vgg_model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "if os.path.exists(\"model/vgg_weights.hdf5\") == False:\n",
    "    model_check_point = ModelCheckpoint(filepath='model/vgg_weights.hdf5', verbose = 1, save_best_only = True)\n",
    "    hist = vgg_model.fit(X_train, y_train, batch_size = 32, epochs = 30, validation_data=(X_test, y_test), callbacks=[model_check_point], verbose=1)\n",
    "    f = open('model/vgg_history.pckl', 'wb')\n",
    "    pickle.dump(hist.history, f)\n",
    "    f.close()    \n",
    "else:\n",
    "    vgg_model.load_weights(\"model/vgg_weights.hdf5\")\n",
    "#perform prediction on test data using global model weights\n",
    "predict = vgg_model.predict(X_test)\n",
    "predict = np.argmax(predict, axis=1)\n",
    "y_test1 = np.argmax(y_test, axis=1)\n",
    "#call this function to calculate accuracy\n",
    "calculateMetrics(\"VGG19\", predict, y_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51251bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot all algorithm performance in tabukar format\n",
    "import pandas as pd\n",
    "df = pd.DataFrame([['CNN Client1 Local','Accuracy',accuracy[0]],['CNN Client1 Local','Precision',precision[0]],['CNN Client1 Local','Recall',recall[0]],['CNN Client1 Local','FSCORE',fscore[0]],\n",
    "                   ['CNN Client2 Local','Accuracy',accuracy[1]],['CNN Client2 Local','Precision',precision[1]],['CNN Client2 Local','Recall',recall[1]],['CNN Client2 Local','FSCORE',fscore[1]],\n",
    "                   ['Global CNN Model','Accuracy',accuracy[2]],['Global CNN Model','Precision',precision[2]],['Global CNN Model','Recall',recall[2]],['Global CNN Model','FSCORE',fscore[2]],\n",
    "                   ['VGG19 Model','Accuracy',accuracy[3]],['VGG19 Model','Precision',precision[3]],['VGG19 Model','Recall',recall[3]],['VGG19 Model','FSCORE',fscore[3]],\n",
    "                  ],columns=['Parameters','Algorithms','Value'])\n",
    "df.pivot(index=\"Parameters\", columns=\"Algorithms\", values=\"Value\").plot(kind='bar', figsize=(6, 3))\n",
    "plt.title(\"All Algorithms Performance Graph\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf44ab96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#display all algorithm performnace\n",
    "algorithms = ['CNN Client1 Local', 'CNN Client2 Local', 'CNN Global Weights', 'VGG19 Model']\n",
    "data = []\n",
    "for i in range(len(accuracy)):\n",
    "    data.append([algorithms[i], accuracy[i], precision[i], recall[i], fscore[i]])\n",
    "data = pd.DataFrame(data, columns=['Algorithm Name', 'Accuracy', 'Precision', 'Recall', 'FSCORE'])\n",
    "data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88992a3-328e-471f-9ed4-213df766f112",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load Yolo Model\n",
    "yolo_model = YOLO(\"model/best.pt\")\n",
    "print(\"Yolo Model Loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef72ef6-86a5-4e94-a39c-6c122e2d4ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectDisorder(frame):\n",
    "    global yolo_model\n",
    "    detections = yolo_model(frame)[0]\n",
    "    # loop over the detections\n",
    "    for data in detections.boxes.data.tolist():\n",
    "        # extract the confidence (i.e., probability) associated with the detection\n",
    "        confidence = data[4]\n",
    "        cls_id = data[5]\n",
    "        # filter out weak detections by ensuring the \n",
    "        # confidence is greater than the minimum confidence\n",
    "        if float(confidence) >= CONFIDENCE_THRESHOLD:\n",
    "            xmin, ymin, xmax, ymax = int(data[0]), int(data[1]), int(data[2]), int(data[3])\n",
    "            cv2.rectangle(frame, (xmin, ymin) , (xmax, ymax), GREEN, 2)         \n",
    "    return frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6d5e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=================flask code starts here\n",
    "from flask import Flask, render_template, request, redirect, url_for, session,send_from_directory\n",
    "import base64\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204f9cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(__name__)\n",
    "app.secret_key = 'welcome'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1d02fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/Predict', methods=['GET', 'POST'])\n",
    "def predictView():\n",
    "    return render_template('Predict.html', msg='')\n",
    "\n",
    "@app.route('/index', methods=['GET', 'POST'])\n",
    "def index():\n",
    "    return render_template('index.html', msg='')\n",
    "\n",
    "@app.route('/AdminLogin', methods=['GET', 'POST'])\n",
    "def AdminLogin():\n",
    "    return render_template('AdminLogin.html', msg='')\n",
    "\n",
    "@app.route('/AdminLoginAction', methods=['GET', 'POST'])\n",
    "def AdminLoginAction():\n",
    "    if request.method == 'POST' and 't1' in request.form and 't2' in request.form:\n",
    "        user = request.form['t1']\n",
    "        password = request.form['t2']\n",
    "        if user == \"admin\" and password == \"admin\":\n",
    "            return render_template('AdminScreen.html', msg=\"Welcome \"+user)\n",
    "        else:\n",
    "            return render_template('AdminLogin.html', msg=\"Invalid login details\")\n",
    "\n",
    "@app.route('/Logout')\n",
    "def Logout():\n",
    "    return render_template('index.html', msg='')\n",
    "\n",
    "def getModel():\n",
    "    global global_weight\n",
    "    global_model = Sequential()\n",
    "    global_model.add(Convolution2D(32, (3 , 3), input_shape = (X_train.shape[1], X_train.shape[2], X_train.shape[3]), activation = 'relu'))\n",
    "    global_model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "    global_model.add(Convolution2D(32, (3, 3), activation = 'relu'))\n",
    "    global_model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "    global_model.add(Flatten())\n",
    "    global_model.add(Dense(units = 256, activation = 'relu'))\n",
    "    global_model.add(Dense(units = y_train.shape[1], activation = 'softmax'))\n",
    "    global_model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    #set global weight to global model\n",
    "    global_model.set_weights(global_weight)\n",
    "    return global_model\n",
    "\n",
    "@app.route('/PredictAction', methods=['GET', 'POST'])\n",
    "def PredictAction():   \n",
    "    if request.method == 'POST':\n",
    "        file = request.files['t1']\n",
    "        img_bytes = file.read()\n",
    "        if os.path.exists(\"static/test.jpg\"):\n",
    "            os.remove(\"static/test.jpg\")\n",
    "        with open('static/test.jpg', mode=\"wb\") as jpg:\n",
    "            jpg.write(img_bytes)\n",
    "        jpg.close()\n",
    "        global_model = getModel()\n",
    "        image = cv2.imread('static/test.jpg')#read test image\n",
    "        img = cv2.resize(image, (32, 32))#resize image\n",
    "        im2arr = np.array(img)\n",
    "        im2arr = im2arr.reshape(1,32,32,3)#convert image as 4 dimension\n",
    "        img = np.asarray(im2arr)\n",
    "        img = img.astype('float32')#convert image features as float\n",
    "        img = img/255 #normalized image\n",
    "        predict = global_model.predict(img)#now predict dog breed\n",
    "        predict = np.argmax(predict)\n",
    "        img = cv2.imread(\"static/test.jpg\")\n",
    "        img = detectDisorder(img)\n",
    "        img = cv2.resize(img, (500,300))#display image with predicted output\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        cv2.putText(img, 'Skin Disorder : '+labels[predict], (10, 25),  cv2.FONT_HERSHEY_SIMPLEX,0.7, (255, 0, 0), 2)\n",
    "        plt.imshow(img)\n",
    "        buf = io.BytesIO()\n",
    "        plt.savefig(buf, format='png', bbox_inches='tight')\n",
    "        plt.close()\n",
    "        img_b64 = base64.b64encode(buf.getvalue()).decode() \n",
    "        return render_template('AdminScreen.html', msg='Skin Disorder : '+labels[predict], img = img_b64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684c145a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa27a46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
